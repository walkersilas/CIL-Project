{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "slope_one_hyperparam_tuning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdpLfVHfRPCy",
        "outputId": "1db8336e-9f23-43cf-a499-1ef825692834"
      },
      "source": [
        "!pip install scikit-surprise\n",
        "!pip install optuna"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-surprise\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/37/5d334adaf5ddd65da99fc65f6507e0e4599d092ba048f4302fe8775619e8/scikit-surprise-1.1.1.tar.gz (11.8MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.15.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp37-cp37m-linux_x86_64.whl size=1617638 sha256=468db30ab94bd14409adf25735ee296f4da77fe68e2cb3777fcb89adfda4b2f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/9c/3d/41b419c9d2aff5b6e2b4c0fc8d25c538202834058f9ed110d0\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.1\n",
            "Collecting optuna\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/18/b49ca91cf592747e19f2d333c2a86cd7c81895b922a5a09adf6335471576/optuna-2.8.0-py3-none-any.whl (301kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 3.1MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.8.2\n",
            "  Downloading https://files.pythonhosted.org/packages/01/1f/43b01223a0366171f474320c6e966c39a11587287f098a5f09809b45e05f/cmaes-0.8.2-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Collecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/80/ef186e599a57d0e4cb78fc76e0bfc2e6953fa9716b2a5cf2de0117ed8eb5/alembic-1.6.5-py2.py3-none-any.whl (164kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 16.4MB/s \n",
            "\u001b[?25hCollecting cliff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/11/aea1cacbd4cf8262809c4d6f95dcb3f2802594de1f51c5bd454d69bf15c5/cliff-3.8.0-py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (20.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.41.1)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Collecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/32/e6/e9ddc6fa1104fda718338b341e4b3dc31cd8039ab29e52fc73b508515361/colorlog-5.0.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.15)\n",
            "Collecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (2.8.1)\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/54/dbc07fbb20865d3b78fdb7cf7fa713e2cba4f87f71100074ef2dc9f9d1f7/Mako-1.1.4-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.2MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/49/b602307aeac3df3384ff1fcd05da9c0376c622a6c48bb5325f28ab165b57/stevedore-3.3.0-py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.1MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/e0/1d4702dd81121d04a477c272d47ee5b6bc970d1a0990b11befa275c55cf2/pbr-5.6.0-py2.py3-none-any.whl (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 13.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.1.0)\n",
            "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.13)\n",
            "Requirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.4.7)\n",
            "Collecting cmd2>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/06/ea782764035efa0633b6353202f3f86b7c390fe11d4dfd33af9b49344130/cmd2-2.0.1-py3-none-any.whl (139kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 14.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.0.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->alembic->optuna) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from PrettyTable>=0.7.2->cliff->optuna) (0.2.5)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/a7/2c/4c64579f847bd5d539803c8b909e54ba087a79d01bb3aba433a95879a6c5/pyperclip-1.8.2.tar.gz\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy>=1.1.0->optuna) (3.4.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-cp37-none-any.whl size=11136 sha256=b9a14d51de6eb19b7d9cbccaf18fcc59855a8275b3c1c8c007b85834c1d87a6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/af/b8/3407109267803f4015e1ee2ff23be0c8c19ce4008665931ee1\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: cmaes, python-editor, Mako, alembic, pbr, stevedore, colorama, pyperclip, cmd2, cliff, colorlog, optuna\n",
            "Successfully installed Mako-1.1.4 alembic-1.6.5 cliff-3.8.0 cmaes-0.8.2 cmd2-2.0.1 colorama-0.4.4 colorlog-5.0.1 optuna-2.8.0 pbr-5.6.0 pyperclip-1.8.2 python-editor-1.0.4 stevedore-3.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeC1TLkwUCYQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7041a801-4516-4402-ae88-43b938ce2f0d"
      },
      "source": [
        "# Mount Google Drive and set data paths.\n",
        "import os\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "DATA_PATH = \"/content/gdrive/My Drive/ETH/Computational Intelligence Lab/CIL-Project/data\"\n",
        "TRAIN_DATA_PATH = os.path.join(DATA_PATH, \"data_train.csv\")\n",
        "TEST_DATA_PATH = os.path.join(DATA_PATH, \"data_test.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTdQmEjzTVbo"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import surprise\n",
        "from surprise import accuracy\n",
        "from surprise.model_selection import cross_validate\n",
        "import optuna"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsMm8IlJThhs"
      },
      "source": [
        "def load_data(file_path: str, full_dataset: bool, train_val_split: bool, random_seed: int = 0, train_size: float = 0):\n",
        "    data_pd = pd.read_csv(file_path)\n",
        "\n",
        "    # Reduce Dataset for Testing\n",
        "    if not full_dataset:\n",
        "        data_pd = data_pd.head(10000)\n",
        "\n",
        "    if train_val_split:\n",
        "        train_pd, val_pd = train_test_split(data_pd, train_size=train_size, random_state=random_seed)\n",
        "        return train_pd, val_pd\n",
        "    else:\n",
        "        return data_pd\n",
        "\n",
        "def __extract_users_items_ratings(data_pd: pd.DataFrame):\n",
        "    users, movies = \\\n",
        "        [np.squeeze(arr) for arr in np.split(data_pd.Id.str.extract('r(\\d+)_c(\\d+)').values.astype(int) - 1, 2, axis=-1)]\n",
        "    ratings = data_pd.Prediction.values\n",
        "    return users, movies, ratings\n",
        "\n",
        "def create_surprise_data(data_pd):\n",
        "    users, movies, ratings = __extract_users_items_ratings(data_pd)\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'users': users,\n",
        "        'movies': movies,\n",
        "        'ratings': ratings\n",
        "    })\n",
        "    reader = surprise.Reader(rating_scale=(1, 5))\n",
        "    return surprise.Dataset.load_from_df(df[['users', 'movies', 'ratings']], reader=reader)\n",
        "\n",
        "def __get_tensors_from_dataframe(data_pd: pd.DataFrame):\n",
        "    users, movies, ratings = __extract_users_items_ratings(data_pd)\n",
        "    users_torch = torch.tensor(users, dtype=torch.int64)\n",
        "    movies_torch = torch.tensor(movies, dtype=torch.int64)\n",
        "    ratings_torch = torch.tensor(ratings, dtype=torch.int64)\n",
        "\n",
        "    return users_torch, movies_torch, ratings_torch\n",
        "\n",
        "\n",
        "def create_dataset(data_pd: pd.DataFrame, test_dataset: bool = False):\n",
        "    users_torch, movies_torch, ratings_torch = __get_tensors_from_dataframe(data_pd)\n",
        "\n",
        "    if not test_dataset:\n",
        "        return TensorDataset(users_torch, movies_torch, ratings_torch)\n",
        "    else:\n",
        "        test_ids = data_pd.Id\n",
        "        return test_ids, TensorDataset(users_torch, movies_torch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7S9Y9-J9Uwl8"
      },
      "source": [
        "random_seed = 42\n",
        "full_dataset = True\n",
        "\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "train_pd = load_data(\n",
        "    file_path=TRAIN_DATA_PATH,\n",
        "    full_dataset=full_dataset,\n",
        "    train_val_split=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lsAHFn4VXR_"
      },
      "source": [
        "train_data = create_surprise_data(train_pd)\n",
        "trainset, testset = surprise.model_selection.train_test_split(train_data, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlaGkYGIqR50"
      },
      "source": [
        "from surprise import SlopeOne\n",
        "\n",
        "def objective(trial):\n",
        "    algo = SlopeOne()\n",
        "    \n",
        "    algo.fit(trainset)\n",
        "    predictions = algo.test(testset)\n",
        "    rmse = accuracy.rmse(predictions)\n",
        "    return rmse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC3XXz8zZd5z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4d59547-880a-41ee-c48c-476d6da9d19b"
      },
      "source": [
        "study = optuna.create_study(direction=\"minimize\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-06-08 19:04:25,110]\u001b[0m A new study created in memory with name: no-name-bb39e27f-0ff5-4438-bc8e-966e7f79b5a8\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CknDptCssujY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fffacb0-5869-4f36-f375-10b5fb71814d"
      },
      "source": [
        "study.optimize(objective, n_trials=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-06-08 19:05:04,506]\u001b[0m Trial 0 finished with value: 0.9995171061773653 and parameters: {}. Best is trial 0 with value: 0.9995171061773653.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "RMSE: 0.9995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkAHfGZos55r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec7aa02f-7948-4495-9649-e01f7d744cc0"
      },
      "source": [
        "# NOTE: We do not prune any trials since surprise does not support partial fit.\n",
        "pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
        "complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
        "\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Study statistics: \n",
            "  Number of finished trials:  1\n",
            "  Number of pruned trials:  0\n",
            "  Number of complete trials:  1\n",
            "Best trial:\n",
            "  Value:  0.9995171061773653\n",
            "  Params: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0YmvhHtzNa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44f74ff6-a932-4fe5-962c-ce4a68c48464"
      },
      "source": [
        "test_pd = load_data(\n",
        "    file_path=TEST_DATA_PATH,\n",
        "    full_dataset=full_dataset,\n",
        "    train_val_split=False\n",
        ")\n",
        "\n",
        "train_data = create_surprise_data(train_pd).build_full_trainset()\n",
        "test_ids, test_data = create_dataset(test_pd, test_dataset=True)\n",
        "test_ids = test_ids.to_numpy()\n",
        "\n",
        "from surprise import SlopeOne\n",
        "\n",
        "algo = SlopeOne()\n",
        "\n",
        "algo.fit(train_data)\n",
        "\n",
        "predictions = []\n",
        "for user, movie in test_data:\n",
        "    prediction = algo.predict(user.item(), movie.item()).est\n",
        "    predictions.append(prediction)\n",
        "\n",
        "output = np.stack((test_ids, predictions), axis=1)\n",
        "\n",
        "pd.DataFrame(output, columns=[\"Id\", \"Prediction\"]).to_csv(\"slopeone_output.csv\", index=None)\n",
        "files.download(\"slopeone_output.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_5d003899-1bfc-4cad-a482-449d43962e7f\", \"slopeone_output.csv\", 34116422)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF5lWKEjmoNN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}